{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:11.573441Z","iopub.execute_input":"2025-01-14T03:35:11.573816Z","iopub.status.idle":"2025-01-14T03:35:11.589607Z","shell.execute_reply.started":"2025-01-14T03:35:11.573788Z","shell.execute_reply":"2025-01-14T03:35:11.588429Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n/kaggle/input/fashionmnist/fashion-mnist_test.csv\n/kaggle/input/fashionmnist/fashion-mnist_train.csv\n/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n/kaggle/input/fashionmnist/train-images-idx3-ubyte\n","output_type":"stream"}],"execution_count":267},{"cell_type":"code","source":"import numpy as np  \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport copy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:11.590953Z","iopub.execute_input":"2025-01-14T03:35:11.591367Z","iopub.status.idle":"2025-01-14T03:35:11.596439Z","shell.execute_reply.started":"2025-01-14T03:35:11.591323Z","shell.execute_reply":"2025-01-14T03:35:11.595270Z"}},"outputs":[],"execution_count":268},{"cell_type":"code","source":"\ndata = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')\ndata_test = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\n\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:11.598190Z","iopub.execute_input":"2025-01-14T03:35:11.598603Z","iopub.status.idle":"2025-01-14T03:35:16.257763Z","shell.execute_reply.started":"2025-01-14T03:35:11.598557Z","shell.execute_reply":"2025-01-14T03:35:16.256723Z"}},"outputs":[{"execution_count":269,"output_type":"execute_result","data":{"text/plain":"   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      0       0       0       0       0       0       0       0       9   \n1      1       0       0       0       0       0       0       0       0   \n2      2       0       0       0       0       0       0      14      53   \n3      2       0       0       0       0       0       0       0       0   \n4      3       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0       8  ...       103        87        56         0         0         0   \n1       0  ...        34         0         0         0         0         0   \n2      99  ...         0         0         0         0        63        53   \n3       0  ...       137       126       140         0       133       224   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel781  pixel782  pixel783  pixel784  \n0         0         0         0         0  \n1         0         0         0         0  \n2        31         0         0         0  \n3       222        56         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>8</td>\n      <td>...</td>\n      <td>103</td>\n      <td>87</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>53</td>\n      <td>99</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>63</td>\n      <td>53</td>\n      <td>31</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>137</td>\n      <td>126</td>\n      <td>140</td>\n      <td>0</td>\n      <td>133</td>\n      <td>224</td>\n      <td>222</td>\n      <td>56</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":269},{"cell_type":"code","source":"data_test.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.259041Z","iopub.execute_input":"2025-01-14T03:35:16.259333Z","iopub.status.idle":"2025-01-14T03:35:16.273915Z","shell.execute_reply.started":"2025-01-14T03:35:16.259307Z","shell.execute_reply":"2025-01-14T03:35:16.272819Z"}},"outputs":[{"execution_count":270,"output_type":"execute_result","data":{"text/plain":"   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      2       0       0       0       0       0       0       0       0   \n1      9       0       0       0       0       0       0       0       0   \n2      6       0       0       0       0       0       0       0       5   \n3      0       0       0       0       1       2       0       0       0   \n4      3       0       0       0       0       0       0       0       0   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0        30        43         0   \n3       0  ...         3         0         0         0         0         1   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel781  pixel782  pixel783  pixel784  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>43</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":270},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Checking null value**","metadata":{}},{"cell_type":"code","source":"print(data.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.275747Z","iopub.execute_input":"2025-01-14T03:35:16.276037Z","iopub.status.idle":"2025-01-14T03:35:16.304402Z","shell.execute_reply.started":"2025-01-14T03:35:16.276011Z","shell.execute_reply":"2025-01-14T03:35:16.303282Z"}},"outputs":[{"name":"stdout","text":"label       0\npixel1      0\npixel2      0\npixel3      0\npixel4      0\n           ..\npixel780    0\npixel781    0\npixel782    0\npixel783    0\npixel784    0\nLength: 785, dtype: int64\n","output_type":"stream"}],"execution_count":271},{"cell_type":"markdown","source":"**Splitting and separating data**\n\nSplitting data into train and val set with a ratio of 0.8","metadata":{}},{"cell_type":"code","source":"# Splitting data\ntarget_column = 'label' \nshuffled_indices = np.random.permutation(len(data))\ndata_shuffled = data.iloc[shuffled_indices]\n\n# Define the split ratio\nsplit_ratio = 0.8\nsplit_index = int(len(data) * split_ratio)\n\n# Split the data\ntrain_data = data_shuffled.iloc[:split_index]\nval_data = data_shuffled.iloc[split_index:]\n\n# Separate features and target variable\nx_train = train_data.drop(target_column, axis=1)\ny_train = train_data[target_column].values.reshape(-1, 1)  # Reshape for consistency\nx_val = val_data.drop(target_column, axis=1)\ny_val = val_data[target_column].values.reshape(-1, 1)  # Reshape for consistency","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.305859Z","iopub.execute_input":"2025-01-14T03:35:16.306256Z","iopub.status.idle":"2025-01-14T03:35:16.371910Z","shell.execute_reply.started":"2025-01-14T03:35:16.306222Z","shell.execute_reply":"2025-01-14T03:35:16.371162Z"}},"outputs":[],"execution_count":272},{"cell_type":"code","source":"y_val.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.372814Z","iopub.execute_input":"2025-01-14T03:35:16.373187Z","iopub.status.idle":"2025-01-14T03:35:16.379645Z","shell.execute_reply.started":"2025-01-14T03:35:16.373120Z","shell.execute_reply":"2025-01-14T03:35:16.378733Z"}},"outputs":[{"execution_count":273,"output_type":"execute_result","data":{"text/plain":"(2000, 1)"},"metadata":{}}],"execution_count":273},{"cell_type":"markdown","source":"**Separating test set**","metadata":{}},{"cell_type":"code","source":"shuffled_indices = np.random.permutation(len(data_test))\ndata_shuffled_test = data_test.iloc[shuffled_indices]\n\n# Separate features and target variable\nx_test = data_shuffled_test.drop(target_column, axis=1)\ny_test = data_shuffled_test[target_column].values.reshape(-1, 1)  # Reshape for consistency\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.380613Z","iopub.execute_input":"2025-01-14T03:35:16.380955Z","iopub.status.idle":"2025-01-14T03:35:16.810970Z","shell.execute_reply.started":"2025-01-14T03:35:16.380921Z","shell.execute_reply":"2025-01-14T03:35:16.809860Z"}},"outputs":[],"execution_count":274},{"cell_type":"markdown","source":"**Checking shape**","metadata":{}},{"cell_type":"code","source":"print(f\"Training features shape: {x_train.shape}\")\nprint(f\"Training labels shape: {y_train.shape}\")\nprint(f\"Validation features shape: {x_val.shape}\")\nprint(f\"Validation labels shape: {y_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.812047Z","iopub.execute_input":"2025-01-14T03:35:16.812321Z","iopub.status.idle":"2025-01-14T03:35:16.818641Z","shell.execute_reply.started":"2025-01-14T03:35:16.812298Z","shell.execute_reply":"2025-01-14T03:35:16.817588Z"}},"outputs":[{"name":"stdout","text":"Training features shape: (8000, 784)\nTraining labels shape: (8000, 1)\nValidation features shape: (2000, 784)\nValidation labels shape: (2000, 1)\n","output_type":"stream"}],"execution_count":275},{"cell_type":"code","source":"# Example: Labels (8000 examples, 1 class per example)\ny_train = pd.Series([0, 1, 2, 3, 4, 5, 6, 7, 8, 9] * 800)\n\n# One-hot encode using pandas\ny_train = pd.get_dummies(y_train).values.T  # Shape: (10, 8000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.822121Z","iopub.execute_input":"2025-01-14T03:35:16.822448Z","iopub.status.idle":"2025-01-14T03:35:16.841598Z","shell.execute_reply.started":"2025-01-14T03:35:16.822420Z","shell.execute_reply":"2025-01-14T03:35:16.840360Z"}},"outputs":[],"execution_count":276},{"cell_type":"code","source":"x_train = x_train.T\nx_val = x_val.T\nprint(\"x_train shape after transpose:\", x_train.shape)  # (784, 8000)\nprint(\"x_val shape after transpose:\", x_val.shape)      # (784, 2000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.843121Z","iopub.execute_input":"2025-01-14T03:35:16.843413Z","iopub.status.idle":"2025-01-14T03:35:16.862090Z","shell.execute_reply.started":"2025-01-14T03:35:16.843387Z","shell.execute_reply":"2025-01-14T03:35:16.860946Z"}},"outputs":[{"name":"stdout","text":"x_train shape after transpose: (784, 8000)\nx_val shape after transpose: (784, 2000)\n","output_type":"stream"}],"execution_count":277},{"cell_type":"markdown","source":"**Visualising the data:**","metadata":{}},{"cell_type":"markdown","source":"Standardising the data ","metadata":{}},{"cell_type":"code","source":"x_train = x_train/255\ny_train = y_train/255\nx_val = x_train/255\ny_val = y_val/255\nx_test = x_test/255\ny_test = y_test/255\n#print(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.863115Z","iopub.execute_input":"2025-01-14T03:35:16.863579Z","iopub.status.idle":"2025-01-14T03:35:16.992473Z","shell.execute_reply.started":"2025-01-14T03:35:16.863533Z","shell.execute_reply":"2025-01-14T03:35:16.991360Z"}},"outputs":[],"execution_count":278},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"```python\ndef initialize_parameters(n_x, n_h, n_y):\n    ...\n    return parameters \ndef linear_activation_forward(A_prev, W, b, activation):\n    ...\n    return A, cache\ndef compute_cost(AL, Y):\n    ...\n    return cost\ndef linear_activation_backward(dA, cache, activation):\n    ...\n    return dA_prev, dW, db\ndef update_parameters(parameters, grads, learning_rate):\n    ...\n    return parameters\n```","metadata":{}},{"cell_type":"markdown","source":"    Argument:\n    n_in -- size of the input layer\n    n_hid -- size of the hidden layer\n    n_out -- size of the output layer\n    \n    Returns:\n    parameters -- python dictionary containing your parameters:\n                    W1 -- weight matrix of shape (n_hid, n_in)\n                    b1 -- bias vector of shape (n_hid, 1)\n                    W2 -- weight matrix of shape (n_out, n_hid)\n                    b2 -- bias vector of shape (n_out, 1)","metadata":{}},{"cell_type":"code","source":"def initialize_parameter(n_in, n_hid, n_out):\n    W1 = np.random.randn(n_hid, n_in)*0.01\n    b1 = np.zeros((n_hid, 1))\n    W2 = np.random.rand(n_out, n_hid)*0.01\n    b2 = np.zeros((n_out, 1))\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2}\n    return parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:16.993668Z","iopub.execute_input":"2025-01-14T03:35:16.994168Z","iopub.status.idle":"2025-01-14T03:35:17.001058Z","shell.execute_reply.started":"2025-01-14T03:35:16.994097Z","shell.execute_reply":"2025-01-14T03:35:16.999474Z"}},"outputs":[],"execution_count":279},{"cell_type":"markdown","source":"\n    Arguments:\n    layer_dims -- python array (list) containing the dimensions of each layer in our network\n    \n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n                    bl -- bias vector of shape (layer_dims[l], 1)\n    ","metadata":{}},{"cell_type":"code","source":"def initialize_parameters_deep(layer_dims):\n    \n    parameters = {}\n    L = len(layer_dims) # number of layers in the network\n\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n        \n        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n\n        \n    return parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.002359Z","iopub.execute_input":"2025-01-14T03:35:17.002671Z","iopub.status.idle":"2025-01-14T03:35:17.024549Z","shell.execute_reply.started":"2025-01-14T03:35:17.002646Z","shell.execute_reply":"2025-01-14T03:35:17.023421Z"}},"outputs":[],"execution_count":280},{"cell_type":"code","source":"def linear_forward(A, W, b):\n    Z = np.dot(W, A) +b\n    cache = (A, W, b)\n    return Z, cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.025661Z","iopub.execute_input":"2025-01-14T03:35:17.026026Z","iopub.status.idle":"2025-01-14T03:35:17.041434Z","shell.execute_reply.started":"2025-01-14T03:35:17.025984Z","shell.execute_reply":"2025-01-14T03:35:17.040251Z"}},"outputs":[],"execution_count":281},{"cell_type":"code","source":"def linear_activation_forward(A_prev, W, b, activation):    \n    if activation == \"sigmoid\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = sigmoid(Z) \n    \n    elif activation == \"relu\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = relu(Z)\n        \n    elif activation == \"softmax\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = softmax(Z)\n        \n    cache = (linear_cache, activation_cache)\n    return A, cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.042569Z","iopub.execute_input":"2025-01-14T03:35:17.042965Z","iopub.status.idle":"2025-01-14T03:35:17.058336Z","shell.execute_reply.started":"2025-01-14T03:35:17.042923Z","shell.execute_reply":"2025-01-14T03:35:17.057095Z"}},"outputs":[],"execution_count":282},{"cell_type":"code","source":"def L_model_forward(X, parameters):\n    caches = []\n    A = X\n    L = len(parameters) // 2 \n    for l in range(1, L):\n        A_prev = A \n        A, cache = linear_activation_forward(A_prev, W = parameters[f\"W{l}\"], b = parameters[f\"b{l}\"], activation = \"relu\") \n        caches.append(cache)\n\n    AL, cache = linear_activation_forward(A, W = parameters[f\"W{L}\"], b= parameters[f\"b{L}\"], activation = \"softmax\")\n    caches.append(cache)\n    \n    return AL, caches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.059483Z","iopub.execute_input":"2025-01-14T03:35:17.059805Z","iopub.status.idle":"2025-01-14T03:35:17.076538Z","shell.execute_reply.started":"2025-01-14T03:35:17.059776Z","shell.execute_reply":"2025-01-14T03:35:17.075463Z"}},"outputs":[],"execution_count":283},{"cell_type":"code","source":"'''def compute_cost(AL, Y):\n    m = Y.shape[1]\n    cost = -(1/m)*np.sum(Y* np.log(AL) + (1-Y) * np.log(1-AL))\n    cost = np.squeeze(cost)   \n    return cost'''\ndef compute_cost(AL, Y):\n    m = Y.shape[1]  # number of examples\n    cost = -np.sum(Y * np.log(AL)) / m\n    AL = np.clip(AL, 1e-10, 1 - 1e-10)\n\n    return cost","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.077593Z","iopub.execute_input":"2025-01-14T03:35:17.077889Z","iopub.status.idle":"2025-01-14T03:35:17.093381Z","shell.execute_reply.started":"2025-01-14T03:35:17.077855Z","shell.execute_reply":"2025-01-14T03:35:17.092225Z"}},"outputs":[],"execution_count":284},{"cell_type":"code","source":"def linear_backward(dZ, cache):\n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n\n    dW = (1/m)*np.dot(dZ, A_prev.T)\n    db = (1/m)*np.sum(dZ, axis =1, keepdims=True)\n    dA_prev = np.dot(W.T, dZ)\n \n    \n    return dA_prev, dW, db","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.094514Z","iopub.execute_input":"2025-01-14T03:35:17.094899Z","iopub.status.idle":"2025-01-14T03:35:17.114943Z","shell.execute_reply.started":"2025-01-14T03:35:17.094854Z","shell.execute_reply":"2025-01-14T03:35:17.113880Z"}},"outputs":[],"execution_count":285},{"cell_type":"code","source":"def relu(Z):\n    A = np.maximum(0, Z)\n    cache = Z\n    return A, cache\n\ndef sigmoid(Z):\n    A = 1 / (1 + np.exp(-Z))\n    cache = Z\n    return A, cache\n    \ndef softmax(Z):\n    # Subtracting the max value from Z for numerical stability\n    shiftZ = Z - np.max(Z, axis=0, keepdims=True)\n    # Calculating the exponentials\n    expZ = np.exp(shiftZ)\n    # Normalizing to get probabilities\n    A = expZ / np.sum(expZ, axis=0, keepdims=True)\n    cache = Z\n    return A, cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.115944Z","iopub.execute_input":"2025-01-14T03:35:17.116362Z","iopub.status.idle":"2025-01-14T03:35:17.126381Z","shell.execute_reply.started":"2025-01-14T03:35:17.116317Z","shell.execute_reply":"2025-01-14T03:35:17.125288Z"}},"outputs":[],"execution_count":286},{"cell_type":"code","source":"def linear_activation_backward(dA, cache, activation):\n\n    linear_cache, activation_cache = cache\n    \n    if activation == \"relu\":\n        dZ =relu_backward(dA, activation_cache)\n        dA_prev, dW, db =  linear_backward(dZ, linear_cache)\n\n    elif activation == \"sigmoid\":\n        dZ =sigmoid_backward(dA, activation_cache)\n        dA_prev, dW, db =  linear_backward(dZ, linear_cache)\n        \n    elif activation == \"softmax\":\n        dZ = softmax_backward(dA, activation_cache)\n        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    \n    return dA_prev, dW, db","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.127561Z","iopub.execute_input":"2025-01-14T03:35:17.127996Z","iopub.status.idle":"2025-01-14T03:35:17.143527Z","shell.execute_reply.started":"2025-01-14T03:35:17.127954Z","shell.execute_reply":"2025-01-14T03:35:17.142439Z"}},"outputs":[],"execution_count":287},{"cell_type":"code","source":"def sigmoid_backward(dA, activation_cache):\n    Z = activation_cache\n    # Sigmoid activation function\n    sigmoid_Z = 1 / (1 + np.exp(-Z))  # Sigmoid output\n    \n    # Derivative of sigmoid\n    dZ = dA * sigmoid_Z * (1 - sigmoid_Z)\n    \n    return dZ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.144553Z","iopub.execute_input":"2025-01-14T03:35:17.144850Z","iopub.status.idle":"2025-01-14T03:35:17.160524Z","shell.execute_reply.started":"2025-01-14T03:35:17.144822Z","shell.execute_reply":"2025-01-14T03:35:17.159506Z"}},"outputs":[],"execution_count":288},{"cell_type":"code","source":"def relu_backward(dA, activation_cache):\n    Z = activation_cache  # Z was stored during the forward pass\n    dZ = np.array(dA, copy=True)  # Initialize dZ as dA\n    \n    # When Z <= 0, set dZ to 0 (ReLU derivative)\n    dZ[Z <= 0] = 0\n    \n    return dZ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.161665Z","iopub.execute_input":"2025-01-14T03:35:17.162098Z","iopub.status.idle":"2025-01-14T03:35:17.179788Z","shell.execute_reply.started":"2025-01-14T03:35:17.162056Z","shell.execute_reply":"2025-01-14T03:35:17.178434Z"}},"outputs":[],"execution_count":289},{"cell_type":"code","source":"def softmax_backward(dA, activation_cache):\n    Z = activation_cache\n    shiftZ = Z-np.max(Z, axis = 0, keepdims=True)\n    expZ = np.exp(shiftZ)\n    A = expZ / np.sum(expZ, axis = 0, keepdims=True)\n     # Compute dZ using the chain rule\n    # dZ = dA * Jacobian of softmax\n    # Jacobian matrix: diag(A) - A * A^T\n    dZ = A * (dA - np.sum(dA * A, axis = 0, keepdims=True))\n    return dZ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.180643Z","iopub.execute_input":"2025-01-14T03:35:17.180927Z","iopub.status.idle":"2025-01-14T03:35:17.203165Z","shell.execute_reply.started":"2025-01-14T03:35:17.180902Z","shell.execute_reply":"2025-01-14T03:35:17.201937Z"}},"outputs":[],"execution_count":290},{"cell_type":"code","source":"def L_model_backward(AL, Y, caches):\n\n    grads = {}\n    L = len(caches) # the number of layers\n    m = AL.shape[1]\n    Y = Y.reshape(AL.shape)\n    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n\n    current_cache = caches[L-1]\n    dA_prev_temp, dW_temp, db_temp = linear_activation_backward(dAL, current_cache, activation=\"softmax\")\n    grads[\"dA\" + str(L-1)] = dA_prev_temp\n    grads[\"dW\" + str(L)] = dW_temp\n    grads[\"db\" + str(L)] = db_temp\n\n    for l in reversed(range(L-1)):\n\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, activation=\"relu\")\n        grads[\"dA\" + str(l)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n    return grads","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.207190Z","iopub.execute_input":"2025-01-14T03:35:17.207528Z","iopub.status.idle":"2025-01-14T03:35:17.222464Z","shell.execute_reply.started":"2025-01-14T03:35:17.207496Z","shell.execute_reply":"2025-01-14T03:35:17.221331Z"}},"outputs":[],"execution_count":291},{"cell_type":"code","source":"def update_parameters(params, grads, learning_rate):\n \n    parameters = copy.deepcopy(params)\n    L = len(parameters) // 2 \n    for l in range(L):\n        parameters[\"W\" + str(l+1)] -= learning_rate * grads[f\"dW{l+1}\"] \n        parameters[\"b\" + str(l+1)] -= learning_rate * grads[f\"db{l+1}\"]\n \n    return parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.223770Z","iopub.execute_input":"2025-01-14T03:35:17.224217Z","iopub.status.idle":"2025-01-14T03:35:17.242021Z","shell.execute_reply.started":"2025-01-14T03:35:17.224172Z","shell.execute_reply":"2025-01-14T03:35:17.240770Z"}},"outputs":[],"execution_count":292},{"cell_type":"code","source":"def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n \n    np.random.seed(1)\n    costs = []            \n    parameters = initialize_parameters_deep(layers_dims)\n\n    for i in range(0, num_iterations):\n\n        AL, caches = L_model_forward(X, parameters)\n\n        cost = compute_cost(AL,Y)\n     \n        grads = L_model_backward(AL, Y, caches)\n\n        parameters = update_parameters(parameters, grads, learning_rate)\n   \n        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n        if i % 100 == 0 or i == num_iterations:\n            costs.append(cost)\n    \n    return parameters, costs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.243109Z","iopub.execute_input":"2025-01-14T03:35:17.243467Z","iopub.status.idle":"2025-01-14T03:35:17.254973Z","shell.execute_reply.started":"2025-01-14T03:35:17.243435Z","shell.execute_reply":"2025-01-14T03:35:17.253672Z"}},"outputs":[],"execution_count":293},{"cell_type":"code","source":"n_in = 784     # num_px * num_px * 3\nn_hid = 2\nn_out = 10\nlayers_dims = (n_in, n_hid, n_out)\nlearning_rate = 0.0075","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.255968Z","iopub.execute_input":"2025-01-14T03:35:17.256310Z","iopub.status.idle":"2025-01-14T03:35:17.276846Z","shell.execute_reply.started":"2025-01-14T03:35:17.256266Z","shell.execute_reply":"2025-01-14T03:35:17.275443Z"}},"outputs":[],"execution_count":294},{"cell_type":"code","source":"# Train the model and get the parameters and costs\nparameters, costs = L_layer_model(x_train, y_train, layers_dims=(n_in, n_hid, n_out), num_iterations=1, print_cost=False)\n\n# Print the cost after the first iteration\nprint(\"Cost after first iteration: \" + str(costs[0]))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.278032Z","iopub.execute_input":"2025-01-14T03:35:17.278368Z","iopub.status.idle":"2025-01-14T03:35:17.351655Z","shell.execute_reply.started":"2025-01-14T03:35:17.278333Z","shell.execute_reply":"2025-01-14T03:35:17.350067Z"}},"outputs":[{"name":"stdout","text":"Cost after iteration 0: 0.009029750967739038\nCost after first iteration: 0.009029750967739038\n","output_type":"stream"}],"execution_count":295},{"cell_type":"code","source":"def compute_accuracy(AL, Y):\n    \"\"\"\n    AL -- The predicted probabilities (after softmax)\n    Y -- The true labels (one-hot encoded)\n    \"\"\"\n    predictions = np.argmax(AL, axis=0)  # Convert probabilities to class labels (index of max probability)\n    labels = np.argmax(Y, axis=0)  # True labels\n    accuracy = np.mean(predictions == labels)  # Compute accuracy\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.352796Z","iopub.execute_input":"2025-01-14T03:35:17.353337Z","iopub.status.idle":"2025-01-14T03:35:17.362602Z","shell.execute_reply.started":"2025-01-14T03:35:17.353289Z","shell.execute_reply":"2025-01-14T03:35:17.361083Z"}},"outputs":[],"execution_count":296},{"cell_type":"markdown","source":"    \n    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n    \n    Arguments:\n    X -- input data, of shape (n_x, number of examples)\n    Y -- true \"label\" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples)\n    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n    learning_rate -- learning rate of the gradient descent update rule\n    num_iterations -- number of iterations of the optimization loop\n    print_cost -- if True, it prints the cost every 100 steps\n    \n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \n","metadata":{}},{"cell_type":"code","source":"def L_layer_model(X, Y, X_val, Y_val, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n\n    np.random.seed(1)\n    costs = []                         # keep track of cost\n    train_accuracies =[]\n    val_accuracies = []\n    # Parameters initialization.\n    parameters = initialize_parameters_deep(layers_dims)\n\n    # Loop (gradient descent)\n    for i in range(0, num_iterations):\n\n        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SOFTMAX\n        AL, caches = L_model_forward(X, parameters)\n        \n        # Compute cost.\n        cost = compute_cost(AL,Y)\n\n        # Backward propagation.\n        grads = L_model_backward(AL, Y, caches)\n \n        # Update parameters.\n        parameters = update_parameters(parameters, grads, learning_rate)\n\n        # Compute accuracy for training set\n        train_accuracy = compute_accuracy(AL, Y)\n        train_accuracies.append(train_accuracy)\n        \n        # Compute accuracy for validation set\n        AL_val, _ = L_model_forward(X_val, parameters)\n        val_accuracy = compute_accuracy(AL_val, Y_val)\n        val_accuracies.append(val_accuracy)\n        \n        \n        # Print the cost every 100 iterations\n        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n            print(f\"Iteration {i}: Cost = {cost}, Train Accuracy = {train_accuracy}, Validation Accuracy = {val_accuracy}\")\n            #print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n        if i % 100 == 0 or i == num_iterations:\n            costs.append(cost)\n    \n    return parameters, costs, train_accuracies, val_accuracies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.363927Z","iopub.execute_input":"2025-01-14T03:35:17.364459Z","iopub.status.idle":"2025-01-14T03:35:17.386250Z","shell.execute_reply.started":"2025-01-14T03:35:17.364400Z","shell.execute_reply":"2025-01-14T03:35:17.383623Z"}},"outputs":[],"execution_count":297},{"cell_type":"code","source":"print(\"Cost after first iteration: \" + str(costs[0]))\n\nparameters, costs = L_layer_model(x_train, y_train, x_val, y_val, layers_dims, num_iterations = 300, print_cost = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:17.387506Z","iopub.execute_input":"2025-01-14T03:35:17.388014Z","iopub.status.idle":"2025-01-14T03:35:38.442470Z","shell.execute_reply.started":"2025-01-14T03:35:17.387966Z","shell.execute_reply":"2025-01-14T03:35:38.440892Z"}},"outputs":[{"name":"stdout","text":"Cost after first iteration: 0.009029750967739038\nIteration 0: Cost = 0.009029750967739038, Train Accuracy = 0.099375, Validation Accuracy = 0.02675\nIteration 100: Cost = 0.009029750830355785, Train Accuracy = 0.100375, Validation Accuracy = 0.0\nIteration 200: Cost = 0.009029750695912832, Train Accuracy = 0.100125, Validation Accuracy = 0.0\nIteration 299: Cost = 0.009029750565709135, Train Accuracy = 0.100375, Validation Accuracy = 0.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-298-7fef3c198677>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cost after first iteration: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL_layer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"],"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error"}],"execution_count":298},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 5, figsize=(12, 5)) \n\n# Flatten the axes array to iterate through each subplot\naxes = axes.flatten()\n\n# Loop through the first 25 images in x_train\nfor i in range(25):\n    image = x_train.iloc[i].values.reshape(28, 28)  # Reshape to 28x28\n    label = y_train[i][0]  # Get the label for the image\n    \n    # Plot the image in the corresponding subplot\n    axes[i].imshow(image, cmap='gray')\n    axes[i].set_title(f\"Label: {label}\", fontsize=8)\n    axes[i].axis('off')  # Hide the axis for a cleaner view\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-14T03:35:38.443330Z","iopub.status.idle":"2025-01-14T03:35:38.443883Z","shell.execute_reply":"2025-01-14T03:35:38.443647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}